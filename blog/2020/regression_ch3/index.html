<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> RA ch3 Inferences in Regression and Correlation Analysis | Hyemin Gu </title> <meta name="author" content="Hyemin Gu"> <meta name="description" content="Lecture note chapter 3 for regression analysis taught by Hyemin Gu in 2020"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/kitty.png?29333e1d6c912d924a80157ab1e4b645"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hyemingu.github.io/blog/2020/regression_ch3/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hyemin</span> Gu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">RA ch3 Inferences in Regression and Correlation Analysis</h1> <p class="post-meta"> Created in July 02, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> statistics</a>   <a href="/blog/tag/lecture-note"> <i class="fa-solid fa-hashtag fa-sm"></i> lecture_note</a>   <a href="/blog/tag/tutorial"> <i class="fa-solid fa-hashtag fa-sm"></i> tutorial</a>   ·   <a href="/blog/category/teaching"> <i class="fa-solid fa-tag fa-sm"></i> teaching</a>   <a href="/blog/category/regression-analysis"> <i class="fa-solid fa-tag fa-sm"></i> regression_analysis</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="ch-3-inferences-in-regression-and-correlation-analysis">Ch 3: Inferences in Regression and Correlation Analysis</h1> <p>In Ch 1, <strong>normal error regression model</strong> (\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\) where \(\epsilon_i \sim N(0, \sigma^2), \epsilon_i \perp \epsilon_j\) for \(i \neq j\)) is introduced by adding an assumption that each error term follows normal distribution.</p> <p>From a good property of normal distribution (<em>Summation of random variables also follows normal distribution where each of them follows normal distribution.</em> ), we could notice that the response \(Y_i\), and coefficients \(\beta_0\), \(\beta_1\) follow normal distribution. This allows statistical tests for these random variables.</p> <h2 id="outline">Outline</h2> <ol> <li>Inference of variables of interest <ul> <li>inference of \(\beta_1\)</li> <li>inference of \(\beta_0\)</li> <li>interval estimation of \(\hat{Y_h} = b_0 + b_1 X_h\)</li> <li>prediction of \(Y_{h,new} = \beta_0 + \beta_1 X_h + \epsilon_{h,new}\)</li> </ul> </li> <li>ANOVA apporach to regression <ul> <li>ANOVA table</li> <li>F-test</li> <li>measure of linear association</li> </ul> </li> </ol> <hr> <h2 id="1-inference-of-variables-of-interest">1. Inference of variables of interest</h2> <p>From now on, we assume that all the linear regression model below refer to normal error regresion model.</p> <h3 id="inference-of-beta_1">inference of \(\beta_1\)</h3> <p>To see if \(Y\) is linear to \(X\), apply a test if the slope of the regression line is zero or not. \(H_0: \beta_1=0\), \(H_1: \beta_1 \neq 0\) estimator of \(\beta_1\):</p> \[b_1 = \frac{\sum_i (X_i-\bar{X})(Y_i-\bar{Y})}{\sum_i (X_i-\bar{X})^2}\] <p>where \(E(b_1) = \beta_1\), and \(\sigma^2(b_1) = Var(b_1) = \frac{\sigma^2}{\sum (X_i -\bar{X})^2}\)</p> <blockquote> <p><u>Proof</u> &gt; \(b_1\) is an unbiased estimator of \(\beta_1\). We use the fact that \(\beta_1\) is linear to \(Y_i\)’s. \(b_1 = \sum_i c_i Y_i\), where \(c_i = \frac{X_i - \bar{X}}{\sum_i (X_i - \bar{X})^2}\). Since \(Y_i\)’s are independent to each other, \(\sigma^2(b_1) = \sum_i c_i^2 Var(Y_i) = \sigma^2 \sum_i c_i^2 = \sigma^2 \sum_i [\frac{X_i - \bar{X}}{\sum_i (X_i - \bar{X})^2}]^2 = \frac{\sigma^2}{\sum_i (X_i - \bar{X})^2}\)</p> </blockquote> <p>Therefore, it is derived that <strong>\(b_1 \sim N(\beta_1, \frac{\sigma^2}{\sum (X_i - \bar{X})^2})\)</strong> under the normal error regression model. Here, \(\sigma^2\) is typically unknown, and so it is estimated by \(s^2 = MSE = SSE/(n-2)\). We write \(s^2(b_1) = \frac{s^2}{\sum (X_i - \bar{X})^2}\). Recall that \(\frac{(n-2)s^2}{\sigma^2} \sim \chi^2(n-2)\). This implies that</p> \[\frac{b_1 - \beta_1}{s(b_1)} \sim t(n-2)\] <p><strong>\(1-\alpha\) confidence interval for \(\beta_1\)</strong> \(b_1 \pm s(b_1) t(1-\alpha/2, n-2)\)</p> <p><strong>2-sided test</strong> test statistic \(t^\ast = \frac{b_1-0}{s(b_1)}\) If \(\mid t^\ast\mid \leq t(1-\alpha/2, n-2)\), conclude \(H_0\), otherwise, \(H_1\).</p> <h3 id="inference-of-beta_0">inference of \(\beta_0\)</h3> <p>We can also check if the intercept of the regression line is zero or not. \(H_0: \beta_0=0\), \(H_1: \beta_0 \neq 0\) estimator of \(\beta_0\): \(\)b_0 = \bar{Y} - b_1 \bar{X}\(\) where \(E(b_0) = \beta_0\), and \(\sigma^2(b_0) = Var(b_0) = \sigma^2[\frac{1}{n} + \frac{\bar{X}^2}{\sum (X_i -\bar{X})^2}]\)</p> <blockquote> <p><u>Proof</u> &gt; \(b_0\) is an unbiased estimator of \(\beta_0\).</p> <p>We use the fact that \(\beta_0\) is linear to \(Y_i\)’s. \(b_0 = \sum_i d_i Y_i\), where \(d_i = \frac{1}{n} - c_i \bar{X}\), \(c_i = \frac{X_i - \bar{X}}{\sum_i (X_i - \bar{X})^2}\). Similar to the case of \(\sigma^2(b_1)\), \(\sigma^2(b_0) = \sigma^2 \sum_i d_i^2 = \sigma^2 \sum_i [\frac{1}{n} - c_i \bar{X}]^2 = \sigma^2 [\frac{1}{n} + \frac{\bar{X}^2}{\sum_i (X_i - \bar{X})^2}]\)</p> </blockquote> <p>Therefore, it is derived that <strong>\(b_0 \sim N\left(\beta_0, \sigma^2[\frac{1}{n} + \frac{\bar{X}^2}{\sum (X_i -\bar{X})^2}]\right)\)</strong> under the normal error regression model. Here, we substitue \(\sigma^2\) by \(MSE\) and write \(s^2(b_0) = s^2[\frac{1}{n} + \frac{\bar{X}^2}{\sum (X_i -\bar{X})^2}]\). Recall that \(\frac{(n-2)s^2}{\sigma^2} \sim \chi^2(n-2)\). This implies that \(\)\frac{b_0 - \beta_0}{s(b_0)} \sim t(n-2)\(\)</p> <p><strong>\(1-\alpha\) confidence interval for \(\beta_0\)</strong> \(b_0 \pm s(b_0) t(1-\alpha/2, n-2)\)</p> <p><strong>2-sided test</strong> test statistic \(t^\ast = \frac{b_0 - 0}{s(b_0)}\) If \(\mid t^\ast\mid \leq t(1-\alpha/2, n-2)\), conclude \(H_0\), otherwise, \(H_1\).</p> <h3 id="interval-estimation-of-haty_h--b_0--b_1-x_h">interval estimation of \(\hat{Y_h} = b_0 + b_1 X_h\)</h3> <p>Here, we have a known level \(X_h\), and the goal is to estimate the mean response \(\hat{Y_h}\).</p> <p>We have \(E(\hat{Y_h}) = E(Y_h) = \beta_0 + \beta_1 X_h\), and \(\sigma^2(\hat{Y_h}) = \sigma^2 [\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum_i (X_i - \bar{X})^2} ]\).</p> <blockquote> <p><u>Proof</u> &gt; \(\sigma^2(\hat{Y_h}) = \sigma^2(b_0 + b_1 X_h) = \sigma^2 (\bar{Y} - b_1 (X_h - \bar{X}))\) Since \(\bar{Y} \perp b_1\), \(\sigma^2 (\bar{Y} - b_1 (X_h - \bar{X})) = \sigma^2 (\bar{Y}) + \sigma^2(b_1 (X_h-\bar{X}))\) &gt; \(= \frac{\sigma^2}{n} + \frac{\sigma^2}{\sum_i (X_i - \bar{X})^2}(X_h - \bar{X})^2 = \sigma^2 [\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum_i (X_i - \bar{X})^2}]\)</p> </blockquote> <p><u>Note</u> The variance of \(\hat{Y_h}\) increases if \(X_h\) is far from \(\bar{X}\).</p> <p>We conclude that <strong>\(\hat{Y_h} \sim N\left(\beta_0 + \beta_1 X_h, [\frac{1}{n} + \frac{(X_h - \bar{X})^2}{\sum_i (X_i - \bar{X})^2} ]\right)\)</strong>. Confidence interval and stastistical test follows.</p> <h3 id="prediction-of-y_hnew--beta_0--beta_1-x_h--epsilon_hnew">prediction of \(Y_{h,new} = \beta_0 + \beta_1 X_h + \epsilon_{h,new}\)</h3> <p>Here, we have an unknown data \((X_h, Y_{h,new})\), which is expected to be came out from the regression model. The goal is to predict the confidence interval for the new data \((X_h, Y_{h,new})\). The new data could be written as \(Y_{h,new} = \beta_0 + \beta_1 X_h + \epsilon_{h,new}\) where \(\epsilon_{h,new} \sim N(0, \sigma^2)\).</p> <p><strong>When the parameters \((\beta_0, \beta_1, \sigma^2)\) are known</strong> we can obtain the mean \(E(Y_{h,new})\). This makes it easy to find out \(Y_{h,new} \sim N(E(Y_{h,new}), \sigma^2)\). The confidence interval is given as <strong>\(E(Y_{h,new}) \pm z(1-\alpha/2)\sigma\)</strong>.</p> <p><strong>When the parameters are unknown</strong> we cannot access the mean \(E(Y_{h,new})\), and use the regression function value \(\hat{Y_{h,new}}\) as an alternative. Also, we cannot be certain of the location of the distribution of \(Y\). The prediction limits for \(Y_{h,new}\) in this case must take account of two elements,</p> <ol> <li>variation in possible location of the distribution of \(Y\)</li> <li>variation within the probability distribution of \(Y\).</li> </ol> <p><u>Note</u> \(s^2(pred) = MSE + s^2(\hat{Y_{h,new}})\)</p> <p>Confidence interval and stastistical test follows.</p> <h2 id="2-anova-apporach-to-regression">2. ANOVA apporach to regression</h2> <p>Once a regression line \(\hat{Y}\) is obtained, we have the formula: \(\)\sum_i(Y_i - \bar{Y})^2 = \sum_i(Y_i - \hat{Y_i})^2 + \sum_i(\hat{Y_i} - \bar{Y})^2\(\)</p> <p><u>Notation</u></p> <ul> <li>Sum of Square TOtal \(SSTO = \sum_i(Y_i - \bar{Y})^2\) : <br>\(\ell_2\) or Euclidean distance between each response \(Y_i\) and the sample mean \(\bar{Y}\), 평균값과의 차이</li> <li>Sum of Squared Error \(SSE = \sum_i(Y_i - \hat{Y_i})^2\) : <br>\(\ell_2\) distance between the response \(Y_i\) and the regression line \(\hat{Y_i}\), regression curve와의 차이/regression curve로 설명되지 않는 부분</li> <li>Sum of Square Regression \(SSR = \sum_i(\hat{Y_i} - \bar{Y})^2\) :<br>평균값 fitting 대비 regression line fitting이 얻은 설명력<br>cf) \(SSR = b_1^2 \sum_i(\hat{X_i} - \bar{X})^2\)</li> </ul> <p><u>Note</u> \(Y - \hat{Y} \perp \hat{Y} - \bar{Y}\)</p> <h3 id="anova-table">ANOVA table</h3> <table> <thead> <tr> <th> </th> <th>SS</th> <th>df</th> <th>MS</th> <th>E(MS)</th> </tr> </thead> <tbody> <tr> <td>R</td> <td>\(\sum_i(\hat{Y_i} - \bar{Y})^2\)</td> <td>1</td> <td>\(SSR\)</td> <td>\(\sigma^2 + \beta_1^2\sum_i(X_i-\bar{X})^2\)</td> </tr> <tr> <td>E</td> <td>\(\sum_i(Y_i - \hat{Y_i})^2\)</td> <td>\(n-2\)</td> <td>\(SSR/(n-2)\)</td> <td>\(\sigma^2\)</td> </tr> <tr> <td>TO</td> <td>\(\sum_i(Y_i - \bar{Y})^2\)</td> <td>\(n-1\)</td> <td> </td> <td> </td> </tr> </tbody> </table> <h3 id="f-test">F-test</h3> <p>We’ve seen applying T-test to see if there is a linear relationship between \(X\) and \(Y\). There is another way using F-test.</p> <p>\(H_0: \beta_1=0\), \(H_1: \beta_1 \neq 0\) test statistic: \(F^\ast = \frac{MSR}{MSE} = \frac{SSR/1}{SSE/(n-2)} \sim F(1, n-2)\) If \(F^\ast \leq F(1-\alpha, 1, n-2)\), conclude \(H_0\), otherwise, conclude \(H_1\).</p> <p><u>Note</u></p> <ul> <li>F-test is one-tailed.</li> <li>\(F^\ast = \frac{SSR/1}{SSE/(n-2)} = \frac{b_1^2 \sum_i(X_i -\bar{X})^2}{MSE}\) <br>Recall that \(s^2(b_1) = \frac{MSE}{\sum_i(X_i-\bar{X})^2}\) <br>\(\therefore F^\ast = \left(T^\ast\right)^2\)</li> </ul> <h3 id="measure-of-linear-association">measure of linear association</h3> <p>We introduce one more approach to confirm the linearity.</p> <p><strong>coefficient of determination (결정계수)</strong> \(R^2 = \frac{SSR}{SSTO} = 1- \frac{SSE}{SSTO}\), \(0\leq R^2 \leq 1\) If \(R^2 \approx 1\), we can say there is a strong linear relationship between \(X\) and \(Y\). cf) Coefficient of correlation \(r\) (상관계수) has the relationship \(r^2 = R^2\). The difference is \(r\) has a sign. This could be calculated.</p> <p>However, the population correlation coefficient remains unknown. Therefore it is estimated by \(r\). In a normal correlation model, MLE of \(\rho_{xy}\) : \(r_{xy} = \frac{\sum_i (X_i-\bar{X})(Y_i-\bar{Y})}{\sqrt{\sum_i(X_i-\bar{X})^2 \sum_j (Y_j-\bar{Y})^j}}\)</p> <p>\(H_0 : \rho_{xy} = 0\) test statistic: \(t^\ast = \frac{r}{\sqrt{1-r^2}} sqrt{n-2}\)</p> <p>If \(\mid t^\ast\mid \leq t(1-\alpha/2, n-2)\), conclude \(H_0\), otherwise, \(H_1\).</p> <hr> <p>Once we construct a model, we should make sure that it is valid. We’ve seen methods from statistical inference up to now. But there are more intuitive ways using visual plots. Next time, we will find which plots are useful to check the validity of a model.</p> <hr> <p>Here are the jupyter notebook scripts <a href="https://github.com/HyeminGu/Regression_R_tutorials/blob/main/Regression_2_Verification_of_Linear_Regression.ipynb" rel="external nofollow noopener" target="_blank">verification of linear model (\(R^2\), inference on variables)</a> and <a href="https://github.com/HyeminGu/Regression_R_tutorials/blob/main/Regression_4_Prediciton.ipynb" rel="external nofollow noopener" target="_blank">prediction</a> to run several practice codes using R.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/ICERM_poster_GPA/">Lipschitz Regularized Gradient Flows and Latent Generative Particles</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/sample_generation_through_gpa_by_gradient_flow/">Sample generation from unknown distributions - Particle Descent Algorithm induced by (f, Γ)-gradient flow</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/python_ode_solving/">Python ODE solving tutorial</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hyemin Gu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"repositories",description:"Github repositories for coding works.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-lipschitz-regularized-gradient-flows-and-latent-generative-particles",title:"Lipschitz Regularized Gradient Flows and Latent Generative Particles",description:"This is a poster for Optimal Transport in Data Science - ICERM 2023.",section:"Posts",handler:()=>{window.location.href="/blog/2023/ICERM_poster_GPA/"}},{id:"post-sample-generation-from-unknown-distributions-particle-descent-algorithm-induced-by-f-\u03b3-gradient-flow",title:"Sample generation from unknown distributions - Particle Descent Algorithm induced by (f, \u0393)-gradient...",description:"This is a 2022 Spring Project paper/presentation slide for the Stochastic processes class.",section:"Posts",handler:()=>{window.location.href="/blog/2022/sample_generation_through_gpa_by_gradient_flow/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-python-ode-solving-tutorial",title:"Python ODE solving tutorial",description:"These are 3 days tutorials(videos, slides, jupyter notebooks) for solving ODEs using Python numerical ODE solvers and introducing PINNs. It was a part of 2021 Fall Nonlinear dynamics class. Conducted by T.A. Hyemin Gu.",section:"Posts",handler:()=>{window.location.href="/blog/2021/python_ode_solving/"}},{id:"post-learning-operators",title:"Learning operators",description:"This is a review presentation slide delivered in machine learning reading seminar in 2021.",section:"Posts",handler:()=>{window.location.href="/blog/2021/learning_operator/"}},{id:"post-lorenz-equations-for-atmospheric-convection-modeling",title:"Lorenz Equations for Atmospheric Convection Modeling",description:"This is a 2021 Spring Project paper for the Applied Math and Math Modeling class.",section:"Posts",handler:()=>{window.location.href="/blog/2021/lorenz_eq/"}},{id:"post-data-dependent-kernel-support-vector-machine-classifiers-in-reproducing-kernel-hilbert-space",title:"Data-dependent Kernel Support Vector Machine classifiers in Reproducing Kernel Hilbert Space",description:"This is a 2021 Spring Project paper for the ST - Math Foundations of Probabilistic Artificial Intelligence II class.",section:"Posts",handler:()=>{window.location.href="/blog/2021/kernelSVM_in_RKHS/"}},{id:"post-r-bioinformatics-2-r-genome-informatics-methodology-and-practice",title:"R Bioinformatics 2. R Genome informatics methodology and practice.",description:"This book is a tutorial for R Bioinformatics practices in 2020 organized by Hyemin Gu and Yijun Kim in Ewha Womans University Mokdong hospital. The tutorial focuses on gene expression data analysis.",section:"Posts",handler:()=>{window.location.href="/blog/2020/r_bioinformatics/"}},{id:"post-r-bioinformatics-1-r-statistics",title:"R Bioinformatics 1. R Statistics.",description:"This book is 6 days classes lecture notes for R Bioinformatics class in 2020 taught by Hyemin Gu. The lecture was done by line-by-line code running and its explanation.",section:"Posts",handler:()=>{window.location.href="/blog/2020/r_statistics/"}},{id:"post-ra-ch12-autocorrelation-in-time-series-data",title:"RA ch12 Autocorrelation in time series data",description:"Lecture note chapter 12 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch12/"}},{id:"post-ra-ch11-remedial-measures",title:"RA ch11 Remedial measures",description:"Lecture note chapter 10 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch11/"}},{id:"post-ra-ch10-diagnostics",title:"RA ch10 Diagnostics",description:"Lecture note chapter 10 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch10/"}},{id:"post-ra-ch9-model-selection-and-validation",title:"RA ch9 Model selection and validation",description:"Lecture note chapter 9 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch9/"}},{id:"post-ra-ch8-regression-models-for-quantitative-and-qualitative-predictors",title:"RA ch8 Regression models for Quantitative and Qualitative predictors",description:"Lecture note chapter 8 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch8/"}},{id:"post-ra-ch7-multiple-regression-2",title:"RA ch7 Multiple Regression 2",description:"Lecture note chapter 7 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch7/"}},{id:"post-ra-ch6-multiple-regression-1",title:"RA ch6 Multiple Regression 1",description:"Lecture note chapter 6 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch6/"}},{id:"post-ra-ch5-matrix-approaches-to-simple-linear-regression",title:"RA ch5 Matrix Approaches to Simple Linear Regression",description:"Lecture note chapter 4 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch5/"}},{id:"post-ra-ch4-diagnostics-and-remedial-measures",title:"RA ch4 Diagnostics and Remedial Measures",description:"Lecture note chapter 4 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch4/"}},{id:"post-ra-ch3-inferences-in-regression-and-correlation-analysis",title:"RA ch3 Inferences in Regression and Correlation Analysis",description:"Lecture note chapter 3 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch3/"}},{id:"post-ra-ch2-review-of-mathematical-statistics",title:"RA ch2 Review of Mathematical Statistics",description:"Lecture note chapter 2 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch2/"}},{id:"post-ra-ch1-linear-regression-with-one-predictor-variable",title:"RA ch1 Linear Regression with One Predictor Variable",description:"Lecture note chapter 1 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch1/"}},{id:"post-training-a-2-layer-neural-network-using-svd-generated-weights",title:"Training a 2 layer Neural Network using SVD-generated weights",description:"This is a poster for Joint Mathematics Meetings 2018.",section:"Posts",handler:()=>{window.location.href="/blog/2018/training_nn_from_SVD_weights/"}},{id:"post-necessary-and-sufficient-conditions-for-shortest-vectors-in-lattices-of-low-dimension",title:"Necessary and sufficient conditions for shortest vectors in lattices of low dimension.",description:"This is a poster for Joint Mathematics Meetings 2017.",section:"Posts",handler:()=>{window.location.href="/blog/2017/necessary_and_sufficient_conditions_for_shortest_vectors_in_lattices_of_low_dimension/"}},{id:"news-initiated-a-role-as-a-research-assistant-advised-by-markos-katsoulakis",title:"Initiated a role as a research assistant, advised by Markos Katsoulakis.",description:"",section:"News"},{id:"news-initiated-a-role-as-a-twigs-coordinator",title:"Initiated a role as a TWIGS coordinator.",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-passed-oral-exam",title:"Passed oral exam.",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_3/"}},{id:"news-presented-a-poster-at-optimal-transport-in-data-science-icerm-brown-university",title:"Presented a poster at Optimal Transport in Data Science \u2013 ICERM, Brown university....",description:"",section:"News"},{id:"news-paper-for-lipschitz-regularized-generative-particles-algorithm-was-published-at-siam-data-science",title:"Paper for Lipschitz regularized generative particles algorithm was published at SIAM Data Science....",description:"",section:"News"},{id:"news-paper-for-wasserstein-1-wasserstein-2-generative-flow-was-released-at-arxiv",title:"Paper for Wasserstein-1/Wasserstein-2 generative flow was released at Arxiv.",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%67%75@%75%6D%61%73%73.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Hyemin-Gu-2/","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/HyeminGu","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/hyemin-gu-58127a207","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/hyemin.gu.9022","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>