<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> RA ch1 Linear Regression with One Predictor Variable | Hyemin Gu </title> <meta name="author" content="Hyemin Gu"> <meta name="description" content="Lecture note chapter 1 for regression analysis taught by Hyemin Gu in 2020"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/kitty.png?29333e1d6c912d924a80157ab1e4b645"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hyemingu.github.io/blog/2020/regression_ch1/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hyemin</span> Gu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">RA ch1 Linear Regression with One Predictor Variable</h1> <p class="post-meta"> Created in June 30, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> statistics</a>   <a href="/blog/tag/lecture-note"> <i class="fa-solid fa-hashtag fa-sm"></i> lecture_note</a>   <a href="/blog/tag/tutorial"> <i class="fa-solid fa-hashtag fa-sm"></i> tutorial</a>   ·   <a href="/blog/category/teaching"> <i class="fa-solid fa-tag fa-sm"></i> teaching</a>   <a href="/blog/category/regression-analysis"> <i class="fa-solid fa-tag fa-sm"></i> regression_analysis</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="ch-1-linear-regression-with-one-predictor-variable">Ch 1: Linear Regression with One Predictor Variable</h1> <h2 id="outline">Outline</h2> <ol> <li> <p>Simple Regression Model</p> <ul> <li>Formulation by Least Square Estimation</li> <li>Gauss-Markov theorem</li> <li>Properties of linear regression model</li> <li>Estimation of \(\sigma^2 = Var(E)\)</li> </ul> </li> <li> <p>Normal Error Regression Model</p> <ul> <li>Formulation by Maximum Likelihood Estimation</li> <li>Advantages of Normal error regression model</li> </ul> </li> </ol> <hr> <h2 id="1-simple-regression-model">1. Simple Regression Model</h2> <h3 id="formulation-by-least-square-estimation">Formulation by Least Square Estimation</h3> <p>Let \(Y\) be dependent / response variable, and \(X\) be independent / explanatory / predictor variable. Given \(n\) paired data \((X_i, Y_i), i=1, \cdots, n\), we want to find a <strong>linear function</strong> \(f(x) = \beta_0 + \beta_1 x\) s.t.</p> \[Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, i=1, \cdots, n\] <p>where \(\epsilon_i\) stands for the error between the function value \(f(X_i)\) and the response \(Y_i\), \(E(\epsilon_i)=0\), \(Var(\epsilon_i)=\sigma^2\), \(\epsilon_i \perp \epsilon_j\) for \(i\neq j\).</p> <p>There are various ways to draw a line which crosses the data points \((X_i, Y_i), i=1, \cdots, n\). Among them, it is reasonable to select one with the <strong>least sum of squared errors</strong> \(\sum_i \epsilon_i^2\).</p> <p>Define a function \(Q\) parametrized by \(\beta_0, \beta_1\),</p> \[Q = Q(\beta_0, \beta_1) = \sum_i (Y_i - \beta_0 - \beta_1 X_i)^2 = \sum_i \epsilon_i^2\] <p><u>Note</u></p> <ul> <li>\(Q\) is convex.</li> <li>Every convex function has a global minimum.</li> <li>\(Q\) is differentiable over \(\beta_0, \beta_1\).</li> </ul> <p>By differentiating the function \(Q\) over \(\beta_0, \beta_1\), find a critical point \((b_0, b_1)\) by setting each partial derivative = 0.</p> \[\frac{\partial Q}{\partial \beta_0} = -2 \sum_i (Y_i - \beta_0 - \beta_1 X_i) = 0\] \[\frac{\partial Q}{\partial \beta_1} = -2 \sum_i X_i (Y_i - \beta_0 - \beta_1 X_i) = 0\] <p>The solution for the above simultaneous equations is</p> \[b_0 = E(Y) - b_1 E(X)\] \[b_1 = \frac{E[(X_i-E(X))(Y_i-E(Y))]}{\sum_i (X_i - E(X))^2} = \frac{Cov(X, Y)}{Var(X)}\] <blockquote> <p><u>Proof</u></p> <ol> <li> \[n \beta_0 = \sum_i (Y_i - \beta_1 X_i)\] </li> <li>\(\sum_i X_i (Y_i - \beta_0 - \beta_1 X_i) = \sum_i (X_i - E(X))(Y_i - \beta_0 - \beta_1 X_i)\) \(= \sum_i (X_i - E(X))(Y_i - E(Y) + \beta_1 E(X) - \beta_1 X_i)\)</li> </ol> </blockquote> <p><u>Remark</u></p> <ol> <li>Once a dataset \((X_i, Y_i), i=1, \cdots, n\) is given, \(X_i\)s are known constants. Also, \(E(Y_i) = \beta_0 + \beta_1 X_i\)s are considered as constants.</li> <li>The error term \(\epsilon_i\) is a random variable.</li> <li>\(Y_i\) is the sum of the constant \(\beta_0 + \beta_1 X_i\) and random \(\epsilon_i\). Therefore, \(Y_i\) is also a random variable.</li> <li>Since \(E(\epsilon_i)=0\), &lt;/br&gt;\(E(Y_i)=E(\beta_0 + \beta_1 X_i + \epsilon_i) = \beta_0 + \beta_1 X_i\), and &lt;/br&gt;\(Var(Y_i) = Var(\epsilon_i)=\sigma^2\).</li> </ol> <h3 id="gauss-markov-theorem">Gauss Markov theorem</h3> <p><u>Statement</u> Under the regression model, the least square estimators of regression coefficients \(b_0, b_1\) are</p> <ol> <li>unbiased (i.e. \(E(b_0)=\beta_0, E(b_1)=\beta_1\)) and</li> <li>having minimum variance among all unbiased linear estimators. (i.e. \(Var(b_i) \leq Var(b_i^*), i=0, 1\), \(b_i^*\) unbiased, linear)</li> </ol> <p>Shortly, it is said that “\(b_0, b_1\) are BLUE(best linear unbiased estimator) of \(\beta_0, \beta_1\), respectively.</p> <p><u>Proof</u> go to <a href="https://drive.google.com/file/d/19612eTUYLQTYB2lD9_atC_nFeF5wQXqL/view?usp=sharing" rel="external nofollow noopener" target="_blank">link</a></p> <h3 id="properties-of-linear-regression-model">Properties of linear regression model</h3> <p><u>Notations</u> Observation : \(Y = \beta_0 + \beta_1 X + \epsilon\) Real line : \(E(Y) = \beta_0 + \beta_1 X\) (unknown) Fitted line : \(\hat{Y} = b_0 + b_1 X\) (known)</p> <p>residual : \(e_i = Y - \hat{Y}\) (known) error : \(\epsilon_i = Y - E(Y)\) (unknown)</p> <ol> <li>\(\sum_i e_i = 0\) <blockquote> <p>\(\because \sum_i (Y_i - \hat{Y_i}) = \sum_i (Y_i - b_0 - b_1 X_i) = 0\) by the choice of \(b_0, b_1\)</p> </blockquote> </li> <li>\(\sum_i e_i^2\) is the minimum</li> <li> \[\sum_i Y_i = \sum_i \hat{Y_i}\] </li> <li>\(\sum_i X_i e_i = 0\) (residual \(e\) is orthogonal to \(X\)) <blockquote> <p>\(\because \sum_i X_i e_i = \sum_i (X_i - \bar{X}) e_i = \sum_i (X_i - \bar{X}) (Y_i - (\bar{Y} + b_1 (X_i - \bar{X}) ))\) &gt; \(= \sum_i (X_i - \bar{X}) (Y_i - \bar{Y}) - b_1 \sum_i (X_i - \bar{X})^2\) &gt; \(= \sum_i (X_i - \bar{X}) (Y_i - \bar{Y}) - \frac{\sum_i (X_i - \bar{X}) (Y_i - \bar{Y})}{\sum_i (X_i - \bar{X})^2} \sum_i (X_i - \bar{X})^2 = 0\)</p> </blockquote> </li> <li>\(\sum_i \hat{Y_i}e_i = 0\) (residual \(e\) is orthogonal to the fitted line \(\hat{Y}\))</li> <li>\(\hat{Y_i} = b_0 + b_1 X_i\) (regression line passes through \((\bar{X},\bar{Y})\)) <blockquote> \[\because \hat{Y_i} = \bar{Y} + b_1(X_i - \bar{X})\] </blockquote> </li> </ol> <h3 id="estimation-of-sigma2--vare">Estimation of \(\sigma^2 = Var(E)\)</h3> <p>\(e_i = Y_i - \hat{Y_i}\) Define \(SSE\) (Sum of Squared Error) \(= \sum_i (Y_i - \hat{Y_i})^2 = \sum_i e_i^2\) \(s^2 = MSE\) (Mean Square Error) \(= \frac{SSE}{n-2} = \sum_i \frac{(Y_i - \hat{Y_i})^2}{n-2} = \sum_i \frac{e_i^2}{n-2}\) (\(n-2\) is the <strong>degree of freedom, df</strong> of the model)</p> <p><u>Observation</u></p> <ul> <li>\(E(MSE) = \sigma^2\) (\(s^2\) is an unbiased estimator of \(\sigma^2\))</li> <li> \[Var(\epsilon_i) = \frac{\sum_i \epsilon_i^2}{n}\] </li> </ul> <h2 id="2-normal-error-regression-model">2. Normal Error Regression Model</h2> <h3 id="formulation-by-maximum-likelihood-estimation">Formulation by Maximum Likelihood Estimation</h3> <p>Assuming a normal distribution to the error terms \(\epsilon_i\), we can estimate \(Var(\epsilon_i) = \sigma^2\) as well as \(\beta_0, \beta_1\).</p> <p>Now the formulation is given as \(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\) where \(\epsilon_i \sim N(0, \sigma^2), \epsilon_i \perp \epsilon_j\) for \(i \neq j\), (pdf of \(\epsilon_i\)) \(= \frac{1}{\sqrt{2\pi}\sigma} exp \left(-\frac{\epsilon_i^2}{2 \sigma^2}\right)\)</p> <p>We estimate \(\beta_0, \beta_1\) and \(\sigma^2\) from <strong>Maximum Likelihood Estimation</strong>. Since \(E(Y_i) = \beta_0 + \beta_1 X_i\) and \(Var(Y_i) = \sigma^2\), pdf of \(Y_i\) is given as \(f_i = \frac{1}{\sqrt{2\pi}\sigma} exp \left(-\frac{(Y_i - \beta_0 - \beta_1 X_i)^2}{2 \sigma^2}\right)\).</p> <p>Using the i.i.d. condition of variables \(Y_i\) and \(Y_j\), the <strong>likelihood function, \(L\)</strong> is given as</p> \[L(\beta_0, \beta_1, \sigma^2) = \Pi_i f_i = \frac{1}{(\sqrt{2\pi}\sigma)^n} exp(-\sum_i \frac{(Y_i - \beta_0 - \beta_1 X_i)^2}{2 \sigma^2})\] <p>We maximize \(L\) or \(log L\) by calcuating the critical point. Then the estimators obtained by maximizing likelihood are given as</p> \[\hat{\beta_0} = b_0 = \bar{Y} - b_1 \bar{X}\] \[\hat{\beta_1} = b_1 = \frac{\sum_i (X_i-\bar{X})(Y_i - \bar{Y})}{\sum_i (X_i-\bar{X})^2}\] <p>(same as LSE)</p> \[\hat{\sigma^2} = \frac{\sum_i (Y_i - \hat{\beta_0} - \hat{\beta_1} X_i)^2}{n} = \frac{\sum_i (Y_i - \hat{Y_i})^2}{n}\] <p>cf) \(MSE = s^2 = \frac{\sum_i (Y_i - \hat{Y_i})^2}{n-2}\) is an unbiased estimator of \(\sigma^2\). \(\hat{\sigma^2}\) is not an unbiased estimator of \(\sigma^2\).</p> <h3 id="advantages-of-normal-error-regression-model">Advantages of Normal error regression model</h3> <p>By introducing normal distribution on the error \(\epsilon_i\), we could obtain an estimator of \(\sigma^2\). Also, in the following chapter, we could find out this normality condition enables to calculate confidence intervals to several variables in the linear regression model.</p> <hr> <p>Here is the <a href="https://github.com/HyeminGu/Regression_R_tutorials/blob/main/Regression_1_Simple_Linear_Regression.ipynb" rel="external nofollow noopener" target="_blank">jupyter notebook script</a> to run several practice codes using R.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/ICERM_poster_GPA/">Lipschitz Regularized Gradient Flows and Latent Generative Particles</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/sample_generation_through_gpa_by_gradient_flow/">Sample generation from unknown distributions - Particle Descent Algorithm induced by (f, Γ)-gradient flow</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/python_ode_solving/">Python ODE solving tutorial</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hyemin Gu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"repositories",description:"Github repositories for coding works.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-lipschitz-regularized-gradient-flows-and-latent-generative-particles",title:"Lipschitz Regularized Gradient Flows and Latent Generative Particles",description:"This is a poster for Optimal Transport in Data Science - ICERM 2023.",section:"Posts",handler:()=>{window.location.href="/blog/2023/ICERM_poster_GPA/"}},{id:"post-sample-generation-from-unknown-distributions-particle-descent-algorithm-induced-by-f-\u03b3-gradient-flow",title:"Sample generation from unknown distributions - Particle Descent Algorithm induced by (f, \u0393)-gradient...",description:"This is a 2022 Spring Project paper/presentation slide for the Stochastic processes class.",section:"Posts",handler:()=>{window.location.href="/blog/2022/sample_generation_through_gpa_by_gradient_flow/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-python-ode-solving-tutorial",title:"Python ODE solving tutorial",description:"These are 3 days tutorials(videos, slides, jupyter notebooks) for solving ODEs using Python numerical ODE solvers and introducing PINNs. It was a part of 2021 Fall Nonlinear dynamics class. Conducted by T.A. Hyemin Gu.",section:"Posts",handler:()=>{window.location.href="/blog/2021/python_ode_solving/"}},{id:"post-learning-operators",title:"Learning operators",description:"This is a review presentation slide delivered in machine learning reading seminar in 2021.",section:"Posts",handler:()=>{window.location.href="/blog/2021/learning_operator/"}},{id:"post-lorenz-equations-for-atmospheric-convection-modeling",title:"Lorenz Equations for Atmospheric Convection Modeling",description:"This is a 2021 Spring Project paper for the Applied Math and Math Modeling class.",section:"Posts",handler:()=>{window.location.href="/blog/2021/lorenz_eq/"}},{id:"post-data-dependent-kernel-support-vector-machine-classifiers-in-reproducing-kernel-hilbert-space",title:"Data-dependent Kernel Support Vector Machine classifiers in Reproducing Kernel Hilbert Space",description:"This is a 2021 Spring Project paper for the ST - Math Foundations of Probabilistic Artificial Intelligence II class.",section:"Posts",handler:()=>{window.location.href="/blog/2021/kernelSVM_in_RKHS/"}},{id:"post-r-bioinformatics-2-r-genome-informatics-methodology-and-practice",title:"R Bioinformatics 2. R Genome informatics methodology and practice.",description:"This book is a tutorial for R Bioinformatics practices in 2020 organized by Hyemin Gu and Yijun Kim in Ewha Womans University Mokdong hospital. The tutorial focuses on gene expression data analysis.",section:"Posts",handler:()=>{window.location.href="/blog/2020/r_bioinformatics/"}},{id:"post-r-bioinformatics-1-r-statistics",title:"R Bioinformatics 1. R Statistics.",description:"This book is 6 days classes lecture notes for R Bioinformatics class in 2020 taught by Hyemin Gu. The lecture was done by line-by-line code running and its explanation.",section:"Posts",handler:()=>{window.location.href="/blog/2020/r_statistics/"}},{id:"post-ra-ch12-autocorrelation-in-time-series-data",title:"RA ch12 Autocorrelation in time series data",description:"Lecture note chapter 12 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch12/"}},{id:"post-ra-ch11-remedial-measures",title:"RA ch11 Remedial measures",description:"Lecture note chapter 10 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch11/"}},{id:"post-ra-ch10-diagnostics",title:"RA ch10 Diagnostics",description:"Lecture note chapter 10 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch10/"}},{id:"post-ra-ch9-model-selection-and-validation",title:"RA ch9 Model selection and validation",description:"Lecture note chapter 9 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch9/"}},{id:"post-ra-ch8-regression-models-for-quantitative-and-qualitative-predictors",title:"RA ch8 Regression models for Quantitative and Qualitative predictors",description:"Lecture note chapter 8 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch8/"}},{id:"post-ra-ch7-multiple-regression-2",title:"RA ch7 Multiple Regression 2",description:"Lecture note chapter 7 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch7/"}},{id:"post-ra-ch6-multiple-regression-1",title:"RA ch6 Multiple Regression 1",description:"Lecture note chapter 6 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch6/"}},{id:"post-ra-ch5-matrix-approaches-to-simple-linear-regression",title:"RA ch5 Matrix Approaches to Simple Linear Regression",description:"Lecture note chapter 4 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch5/"}},{id:"post-ra-ch4-diagnostics-and-remedial-measures",title:"RA ch4 Diagnostics and Remedial Measures",description:"Lecture note chapter 4 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch4/"}},{id:"post-ra-ch3-inferences-in-regression-and-correlation-analysis",title:"RA ch3 Inferences in Regression and Correlation Analysis",description:"Lecture note chapter 3 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch3/"}},{id:"post-ra-ch2-review-of-mathematical-statistics",title:"RA ch2 Review of Mathematical Statistics",description:"Lecture note chapter 2 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch2/"}},{id:"post-ra-ch1-linear-regression-with-one-predictor-variable",title:"RA ch1 Linear Regression with One Predictor Variable",description:"Lecture note chapter 1 for regression analysis taught by Hyemin Gu in 2020",section:"Posts",handler:()=>{window.location.href="/blog/2020/regression_ch1/"}},{id:"post-training-a-2-layer-neural-network-using-svd-generated-weights",title:"Training a 2 layer Neural Network using SVD-generated weights",description:"This is a poster for Joint Mathematics Meetings 2018.",section:"Posts",handler:()=>{window.location.href="/blog/2018/training_nn_from_SVD_weights/"}},{id:"post-necessary-and-sufficient-conditions-for-shortest-vectors-in-lattices-of-low-dimension",title:"Necessary and sufficient conditions for shortest vectors in lattices of low dimension.",description:"This is a poster for Joint Mathematics Meetings 2017.",section:"Posts",handler:()=>{window.location.href="/blog/2017/necessary_and_sufficient_conditions_for_shortest_vectors_in_lattices_of_low_dimension/"}},{id:"news-initiated-a-role-as-a-research-assistant-advised-by-markos-katsoulakis",title:"Initiated a role as a research assistant, advised by Markos Katsoulakis.",description:"",section:"News"},{id:"news-initiated-a-role-as-a-twigs-coordinator",title:"Initiated a role as a TWIGS coordinator.",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-passed-oral-exam",title:"Passed oral exam.",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_3/"}},{id:"news-presented-a-poster-at-optimal-transport-in-data-science-icerm-brown-university",title:"Presented a poster at Optimal Transport in Data Science \u2013 ICERM, Brown university....",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_4/"}},{id:"news-paper-for-lipschitz-regularized-generative-particles-algorithm-was-published-at-siam-data-science",title:"Paper for Lipschitz regularized generative particles algorithm was published at SIAM Data Science....",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_5/"}},{id:"news-paper-for-wasserstein-1-wasserstein-2-generative-flow-was-released-at-arxiv",title:"Paper for Wasserstein-1/Wasserstein-2 generative flow was released at Arxiv.",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_6/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%67%75@%75%6D%61%73%73.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Hyemin-Gu-2/","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/HyeminGu","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/hyemin-gu-58127a207","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/hyemin.gu.9022","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>